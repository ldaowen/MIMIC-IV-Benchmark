{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifcation Models Evaluation \n",
    "\n",
    "## 0. Installation requirements\n",
    "This model requires sklearn and sklearn gentics \n",
    "Run the following lines to install if required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install sklearn-genetic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pre-processing \n",
    "\n",
    "## Functions: pre_process data\n",
    "Reads the csv file and converts the outcome and gender column from a boolean type to integer for processing. \n",
    "The data is filtered for mostly empty columns and empty rows. Followed by splitting of the dataset. Finally SMOTE is applied to remove the problem of imbalanced data in the training dataset. \n",
    "\n",
    "## Functions: get_feats\n",
    "Takes in the classification model used as well as the training data available to determine the best features to be used. The evaluation is done using k-fold cross validation technique. \n",
    "\n",
    "## Function: print_results \n",
    "Takes in the model and dataset. Using the training data we fit the model and evaluate the performance on the Training and Test dataset using the F-measure and AUROC scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data():\n",
    "\n",
    "    df = pd.read_csv('Assignment_1_data.csv')\n",
    "    df[\"outcome\"] = df[\"outcome\"].astype(int)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[\"gender\"])\n",
    "    df[\"gender\"] = le.transform(df[\"gender\"])\n",
    "\n",
    "    X = df.copy()\n",
    "\n",
    "    y = X['outcome'].astype(int)\n",
    "    print('Num Samples:', X.shape[0], 'Num Features:', X.shape[1], 'Num intubation', np.sum(y==1))\n",
    "    print(\"Percentage of intubation:\", np.round(np.sum(y==1)/X.shape[0]*100, 3) , \"%\")\n",
    "\n",
    "\n",
    "    num_samples =  X.shape[0]\n",
    "    n_std = 4\n",
    "    for idx, col in enumerate(X.columns):\n",
    "        non_nan_percentage = df[df.columns[idx]].count()/num_samples*100\n",
    "        if non_nan_percentage < 80: \n",
    "            X = X.drop(columns=[col])\n",
    "        else: \n",
    "            if col != 'outcome':\n",
    "                mean = X[col].mean()\n",
    "                sd = X[col].std()\n",
    "                # X = X[(X[col] <= mean+(n_std*sd))]\n",
    "                X = X[(X[col] <= mean+(n_std*sd))] #and X[col] >= mean-(n_std*sd)\n",
    "                X = X[(X[col] >= mean-(n_std*sd))] #and X[col] >= mean-(n_std*sd)\n",
    "                X[col] = (X[col] - X[col].mean()) / X[col].std()\n",
    "\n",
    "    X = X.dropna()\n",
    "    y = X['outcome'].astype(int)\n",
    "    X = X.drop(columns=['outcome'])\n",
    "\n",
    "    print('Num Samples:', X.shape[0], 'Num Features:', X.shape[1], 'Num intubation', np.sum(y==1))\n",
    "    print(\"Percentage of intubation:\", np.round(np.sum(y==1)/X.shape[0]*100, 3) , \"%\")\n",
    "\n",
    "        \n",
    "    X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "    assert y.shape[0] == X.shape[0]\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X, y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_feats(X, y, estimator):\n",
    "    max_feats = 10 ;     n_pop = 100;   cross_prob = 0.8 ; mutation_prob = 0.2 ;   n_gens = 5 ;   t_size = 10;\n",
    "    # estimator = linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "    # estimator = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, max_features='log2')\n",
    "    feat_selector = GeneticSelectionCV(\n",
    "        estimator,\n",
    "        cv=10, #5\n",
    "        verbose=0,\n",
    "        scoring=\"accuracy\",\n",
    "        max_features=max_feats,\n",
    "        n_population=n_pop,\n",
    "        crossover_proba=cross_prob,\n",
    "        mutation_proba=mutation_prob,\n",
    "        n_generations=n_gens,\n",
    "        crossover_independent_proba=0.5,\n",
    "        mutation_independent_proba=0.05,\n",
    "        tournament_size=t_size,\n",
    "        n_gen_no_change=10,\n",
    "        caching=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    feat_selector = feat_selector.fit(X, y)\n",
    "    \n",
    "    selected_feats = X.columns[feat_selector.support_]\n",
    "    print(\"Selected Features:\", selected_feats)\n",
    "    return selected_feats\n",
    "\n",
    "\n",
    "def print_results(y_test, key, clf, X_train,y_train,X_test, case):\n",
    "    start_time = time.time()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    runtime = (time.time() - start_time)\n",
    "\n",
    "\n",
    "    f1_score = metrics.accuracy_score(y_train,y_pred_train)\n",
    "    auroc_train = metrics.roc_auc_score(y_train, y_pred_train)\n",
    "    print(case, \" | Train Set - F1: {0:2f}, AUROC: {1:2f} \".format(f1_score, auroc_train))\n",
    "\n",
    "    \n",
    "    f1_score = metrics.accuracy_score(y_test,y_pred)\n",
    "    auroc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(case, \" -| Test Set F1: {0:2f}, AUROC: {1:2f} \".format(f1_score, auroc, runtime))\n",
    "\n",
    "    return auroc_train, auroc, clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Pre-processing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = pre_process_data()\n",
    "\n",
    "# X_train.to_pickle(\"./X_train.pkl\")  \n",
    "# X_test.to_pickle(\"./X_test.pkl\")  \n",
    "# y_train.to_pickle(\"./y_train.pkl\")  \n",
    "# y_test.to_pickle(\"./y_test.pkl\")  \n",
    "\n",
    "# X_train = pd.read_pickle(\"./X_train_out.pkl\")  \n",
    "# y_train = pd.read_pickle(\"./y_train_out.pkl\")\n",
    "# X_test = pd.read_pickle(\"./X_test_out.pkl\")\n",
    "# y_test = pd.read_pickle(\"./y_test_out.pkl\")\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "print('Train Num Samples:', X_train.shape[0], 'Num Features:', X_train.shape[1], 'Num intubation', np.sum(y_train==1))\n",
    "print(\"Percentage of intubation:\", np.round(np.sum(y_train==1)/X_train.shape[0]*100, 3) , \"%\")\n",
    "\n",
    "print('Test Num Samples:', X_test.shape[0], 'Num Features:', X_test.shape[1], 'Num intubation', np.sum(y_test==1))\n",
    "print(\"Percentage of intubation:\", np.round(np.sum(y_test==1)/X_test.shape[0]*100, 3) , \"%\")\n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selction with Parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_ = {'Logistic Regression' : linear_model.LogisticRegression(solver=\"liblinear\"), \n",
    "            'Decision Tree': DecisionTreeClassifier(criterion='entropy'),\n",
    "            'Random Forest': RandomForestClassifier(),\n",
    "            'Adaboost': AdaBoostClassifier(),\n",
    "            'Gradient Boost': GradientBoostingClassifier(),'SVM': svm.SVC(C=1.0, kernel='linear')}\n",
    "\n",
    "# Parameter tuning grids-------------------------\n",
    "LR_params = [{'C': [1, 10, 100], 'penalty': ['l1', 'l2']}]\n",
    "DT_params = [{'max_depth': [3, 5, 7]}]\n",
    "RF_params = [{'n_estimators': [50, 100, 500], 'max_depth': [3, 5, 7], 'max_samples': [1000, 4000, 8235]}]\n",
    "Gradient_params = [{'learning_rate': [0.001, 0.01, 0.1], 'n_estimators': [10, 50 , 100, 500], 'subsample': [0.5, 0.7, 1.0], 'max_depth': [3, 5, 7]}]\n",
    "Ada_params = [{'learning_rate': [0.001, 0.01, 0.1], 'n_estimators': [10, 50 , 100, 500], 'base_estimator': [DecisionTreeClassifier(max_depth=3, class_weight = 'balanced'), DecisionTreeClassifier(max_depth=5, class_weight = 'balanced'), DecisionTreeClassifier(max_depth=7, class_weight = 'balanced')]}]\n",
    "SVM_params =[{'kernel': ['linear', 'poly', 'rbf'], 'C': [100, 10, 1.0, 0.1, 0.001]}]\n",
    "\n",
    "grid_params ={'Logistic Regression': LR_params,\n",
    "        'Decision Tree': DT_params,\n",
    "        'Random Forest': RF_params,\n",
    "        'Adaboost': Ada_params,\n",
    "        'Gradient Boost': Gradient_params,\n",
    "        'SVM': SVM_params}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "experiment_name_list = [] ; auroc_train_list = [] ; auroc_test = [] ; runtime_list = []; feats_list = []\n",
    "\n",
    "for key in models_:\n",
    "    print(\"------------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "    model = models_[key]\n",
    "    case = copy.deepcopy(key) \n",
    "    auroc_train, auroc , _, y_pred= print_results(y_test, key, model, X_train,y_train,X_test, key)\n",
    "\n",
    "    runtime = time.time() - start_time\n",
    "    RocCurveDisplay.from_predictions(y_true=y_test, y_pred = y_pred, ax = axs[0], label = case + '| (auroc =' + str(np.round(auroc,3)) +')' )\n",
    "    experiment_name_list.append(case); auroc_train_list.append(auroc_train) ; auroc_test.append(auroc); runtime_list.append(runtime)\n",
    "    del model\n",
    "\n",
    "    start_time = time.time()\n",
    "    clf = models_[key]\n",
    "    case = key +\" + Feature Selection\"    \n",
    "    sel_feats = get_feats(X_train,y_train, clf)\n",
    "\n",
    "\n",
    "    auroc_train, auroc, _, y_pred = print_results(y_test, key, clf, X_train[sel_feats],y_train,X_test[sel_feats], key)\n",
    "    RocCurveDisplay.from_predictions(y_true=y_test, y_pred = y_pred, ax = axs[1] ,  label = case + '| (auroc =' + str(np.round(auroc,3)) +')'  )\n",
    "    runtime = time.time() - start_time\n",
    "    experiment_name_list.append(case); auroc_train_list.append(auroc_train) ; auroc_test.append(auroc); runtime_list.append(runtime)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    gsearch = GridSearchCV(clf, grid_params[key], cv = 5, scoring='roc_auc', n_jobs=10)\n",
    "    case = key +\" + FS + Grid search\"       \n",
    "\n",
    "    \n",
    "    auroc_train, auroc, gsearch, y_pred  = print_results(y_test, key, gsearch, X_train[sel_feats],y_train,X_test[sel_feats], key)\n",
    "    RocCurveDisplay.from_predictions(y_true=y_test, y_pred = y_pred, ax = axs[2],  label = case + '| (auroc =' + str(np.round(auroc,3)) +')'  )\n",
    "    print(gsearch.best_params_)\n",
    "    runtime = time.time() - start_time\n",
    "    experiment_name_list.append(case); auroc_train_list.append(auroc_train) ; auroc_test.append(auroc); runtime_list.append(runtime)\n",
    "\n",
    "    results_df = pd.DataFrame(gsearch.cv_results_)\n",
    "    results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "    save_file_path = key + \"_results.csv\"\n",
    "    results_df.to_csv(save_file_path)\n",
    "\n",
    "    feats_list.append('None')\n",
    "    feats_list.append(sel_feats.tolist())\n",
    "    feats_list.append(sel_feats.tolist()+ [gsearch.best_params_])\n",
    "\n",
    "    del clf\n",
    "    # break\n",
    "\n",
    "axs[0].set_title('Baseline')\n",
    "axs[1].set_title('Baseline with Feature Selection')\n",
    "axs[2].set_title('Baseline with Feature Selection and Optimisation')\n",
    "plt.show()\n",
    "\n",
    "results = {'Experiment': experiment_name_list , 'auroc train': auroc_train_list , 'auroc': auroc_test , 'runtime': runtime_list , 'selected feaats': feats_list }\n",
    "df = pd.DataFrame(data=results)\n",
    "df.to_csv(\"Obtained_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db3707226d22d5e3db23ec2a4fc048809fe58768a5a8477fa7abdd5cc6d56113"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('p3.7': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}